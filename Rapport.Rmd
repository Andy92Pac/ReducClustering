---
title: "Rapport"
output:
  pdf_document: default
  html_document: default
---

## Plan

Partie I : Commun à toutes les données

1. Introduction
2. Exploration des données

Partie II : Spécifique à chaque jeu de données

3. Analyse en composante principale
4. Clustering avec package Nbclust
5. Clustering à partir des deux premère composantes
6. Spectral clustering
7. Proposition d'un nombre de classes
8. Modèle de mélange
9. MclustDR
10. Etudes comparatives des performances
11. Cluspa

***
>Librairies

```{r, LibraryCheck, message=FALSE, warning=FALSE}
library(R.matlab)
library(FactoMineR)
library(NbClust)
library(kernlab)
library(Rmixmod)
library(mclust)
library(factoextra)
library(cluster)
library(clustrd)
library(ClusterR)
```


## 1. Introduction 

Nous avons pour but dans ce projet de mettre en corrélation nos compétences acquises dans le cours de réduction de dimension ainsi qu'en modèle de mélange. En appliquant des algotithmes sur différents jeu de données qui ont pour point commun être des bases de données d'images. Une fois ces algorithmes lancé nous devions faire un travail d'analyse, d'interprêtations et de comparaison pour trouver selon nous ce qui nous semble être les solutions les plus cohérentes et meilleures. 

Description des jeu de données : 
------------------------------

**Columbia University Image Library (Coil20 Processed)** : Base de données contenant 1440 images de 20 objets différents pris sous différents angles. Ce jeu de données est composé de 1440 observations et 1024 variables. 
Ces 20 objets forments 20 classes avec 72 individus dans chacune de ces classes. Ces 72 individus correspondent aux 72 photos pris sous différents angles. 
1024 variables représentent les pixels car chaque images mesure 32*32 = 1024 pixels. 

**Japanese Female Facial Expression (JAFFE)** : Base de données contenant 213 photos de 10 femmes représentant 7 émotions (dont une neutre). Ce jeu de données est composé de 213 individus rangés dans un 10 classes qui correspondent aux 10 femmes.
Les 676 variables représentent les pixels car chaque images mesure 26*26 = 676 pixels

**Multi-Feature digit (MFEAT1)** : Cet ensemble de données est constitué de caractéristiques de chiffres manuscrits (0 à 9)
extrait d'une collection de cartes d'utilité néerlandaises. 200 motifs par
classe (pour un total de 2 000 modèles) ont été numérisés en binaire. Ce jeu données est composé de 2000 observations et 240 variables.

**Mixed National Institute of Standards and Technology (MNIST)** : La base MNIST est devenu un test standard1. Elle regroupe 60.000 images d'apprentissage et 10.000 images de test, issues d'une base de données antérieure, appelée simplement NIST1. Ce sont des images en noir et blanc, normalisées centrées de 28 pixels de côté. Ce jeu de données (réduit) est composé de 3495 observations et 784 variables.

***

## 2. Chargement des données

```{r}
coil <- readMat("data/DATA_MATLAB - Projet-master-MLDS/COIL20_1440n_1024d_20c.mat")
jaffe <- readMat("data/DATA_MATLAB - Projet-master-MLDS/jaffe.mat")
mnist <- readMat("data/DATA_MATLAB - Projet-master-MLDS/MNIST5.mat")
mfeat <- readMat("data/DATA_MATLAB - Projet-master-MLDS/MFEAT1.mat")
```

Séparation en data et label
-------------------------

Chaque datasets est au format .mat ils contiennent tous une colonne "Y" correspondants à la classe ou variable à expliquer ainsi que des varibles explicatives ou features "X".

Nous les avons assignées dans des différentes variables pour plus de faciliter et de clarté dans notre code.

```{r}
coil.data <- coil$X
coil.label <- coil$y

jaffe.data <- jaffe$X
jaffe.label <- jaffe$y

mfeat.data <- mfeat$X
mfeat.label <- mfeat$y

mnist.data <- mnist$X
mnist.label <- mnist$y
```


## 3. Analyse en composante principale

Dans cette étude de l'ACP nous allons plus nous intéresser aux individus. Car pour la suite ce qui nous intérèsse est le partitionnement de ceux-là.

Coil data
---------

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
pca.coil <- PCA(coil.data)
```

Obs : ci-dessous on retrouve une visualisation du plan d'individus factorielle issu de l'ACP.(Le cercle de corrélation des variables n'est pas affiché du fait que l'on peux pas distinguer des variables pertinentes ou non dans notre analyse)


![](ACP_Coil.png)

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
fviz_eig(pca.coil, addlabels = TRUE, ylim = c(0, 50),main = "Graphique des valeurs propres cumulées par dimensions")
```

En se basant sur la méthode du coude nous nous assurons bien que les deux composantes (1 et 2) sont les plus répresentative de notre jeu de données de base ainsi notre nuage de point sera le plus représentatif. Mais on remarque aussi qu'en terme de variance expliquée pour les deux dimensions on se retrouve qu'à environ 35% ce qui est faible.

![](coudeMethode.png)

Qualité de représentation : 

De plus on peux s'intéresser à la qualité de représentation du nuage d'individu. Un point est dit bien représenté sur un axe ou un plan factoriel si il est proche de sa projection sur l’axe ou le plan. S’il est éloigné, on dit qu’il est mal représenté. Indicateur =angle formé entre le point et sa projection sur l’axe. Lorsque l’angle est proche de 0, c'est-à-dire que le cosinus est proche de 1, l’individu est bien représenté. Dans le cas inverse, l’angle est proche de 90° et le cosinus est proche de 0

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
fviz_pca_ind (pca.jaffe, col.ind = "cos2",
              gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
              repel = TRUE # Évite le chevauchement de texte
)
```

Cependant comme on peut le voir sur le graphe ci-dessous, au vu du nombre d'observations que l'on à le graphe n'est pas très lisible. On remarque juste des masse de couleurs qui diffère en fonction de la valeurs du cos2 de chaque individu. Donc il est quasi-impossible de dire graphiquement parlant quel individu à une meilleure qualité de représentation qu'un autre. De même que pour la contributions des individus au composantes 1 et 2. 


![](ind_coil.png)


***

Jaffe data
----------

Obs : Ci-dessous on retrouve une visualisation du plan d'individus factorielle issu de l'ACP.(Le cercle de corrélation des variables n'est pas affiché du fait que l'on peux pas distinguer des variables pertinentes ou non dans notre analyse)

De même que pour l'ACP du jeu de données Coil on remarque une répartition des individu très distincte ce qui dans un premier temps peut nous renseigner sur le fait que les individus ne sont pas identiques ou colporte la même informations (présence de doublons)

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
pca.jaffe <- PCA(jaffe.data)
```

![](ACP_jaffe.png)

Méthode du coude : 

Dim 1 = 31,4% variance expliquée (valeurs propres)
Dim 2 = 15% variance expliquée (valeurs propres)

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
fviz_eig(pca.jaffe, addlabels = TRUE, ylim = c(0, 50),main = "Graphique des valeurs propres cumulées par dimensions")
```

![](coude_jaffe.png)

Remarque nous aurions pu utiliser le critère de kaiser ou le critère de Scree-test pour trouver les axes qui nous intèressent.

Qualité de représentation : 

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
fviz_pca_ind (pca.jaffe, col.ind = "cos2",
              gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
              repel = TRUE # Évite le chevauchement de texte
)
```

Il s'agit d'une représentation des individus catégorisé de par leurs valeurs du cos2. On remarque les points présentant des similarité sont regroupés. On remarque 6 foyers. (Nous précisons les foyers ne font en  aucun cas allusion à des partitions ou classes)

![](ind_jaffe.png)


***

Mnist data
----------

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=FALSE,results='hide'}
pca.mnist <- PCA(mnist.data)
```

Obs : Ci-dessous on retrouve une visualisation du plan d'individus factorielle issu de l'ACP.(Le cercle de corrélation des variables n'est pas affiché du fait que l'on peux pas distinguer des variables pertinentes ou non dans notre analyse)


![](ACP_mnist.png)

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=FALSE,results='hide'}
fviz_eig(pca.mnist, addlabels = TRUE, ylim = c(0, 50),main = "Graphique des valeurs propres cumulées par dimensions")
```

![](coude_mnist.png)

Qualité de représentation : 

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=FALSE,results='hide'}
fviz_pca_ind (pca.mnist, col.ind = "cos2",
              gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
              repel = TRUE # Évite le chevauchement de texte
)
```


![](ind_mnist.png)
***

Mfeat data
----------

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=FALSE,results='hide'}
pca.mfeat <- PCA(mfeat.data)
```

Obs : Ci-dessous on retrouve une visualisation du plan d'individus factorielle issu de l'ACP.(Le cercle de corrélation des variables n'est pas affiché du fait que l'on peux pas distinguer des variables pertinentes ou non dans notre analyse)



![](PCA_mfeat.png)


```{r,eval=FALSE, message=FALSE, warning=FALSE, include=FALSE,results='hide'}
fviz_eig(pca.mfeat, addlabels = TRUE, ylim = c(0, 50),main = "Graphique des valeurs propres cumulées par dimensions")
```

![](coude_mfeat.png)

Qualité de représentation : 

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=FALSE,results='hide'}
fviz_pca_ind (pca.mfeat, col.ind = "cos2",
              gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
              repel = TRUE # Évite le chevauchement de texte
)
```


![](ind_mfeat.png)

## 4. Clustering avec package Nbclust 

*En bref* : Le package NbClust inclus une fonction NbClust() qui utilise 30 indices pour déterminer le nombre de clusters et propose d'utiliser le meilleur schéma de clusters à partir des différents résultats obtenus en faisant varier toutes les combinaisons de nombre de clusters (renseigné ou non au préalable par les param min.nc et max.nc) de mesures de distance et de méthodes de clusters.

*Rem* : Nous avons détaillé notre méthodologie de travail pour Coil data --> Kmeans afin de montrer comment nous sommes parvenus aux résultats obtenu ainsi que les deux différentes structure trouvées. Pour le reste nous avons juste affiché les résultats car la méthode est la même.

Coil data
---------

Obs : Les données étant labelisé nous savons que le jeu de données coil contient 20 classes. Le but à travers l'éxecutions de ces algorithmes est de trouver un modèle qui égale au mieux les classes des données

**Kmeans**

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
kmeans.coil = NbClust(data = coil.data, method = "kmeans",min.nc = 10,max.nc = 20)
```

Vote majoritaire propose un regroupement en **10 classes**. 
Cependant selon les index Cubic CLustering Criterion (ccc), l'index Silhouette et l'index Davies and Bouldin (db) proposent un clustering à 20 classes. Avec comme score suivant

```{r}
kmeansCoil20res <- data.frame(CCC="62.3",DB = "1.76",SILHOUETTE = "0.24",row.names = "Score")
kmeansCoil20res
```

Le point commun de ces index est qu'ils mesurent tous la qualité des clusters. Cependant il est assez complexe de les comparer car ils ne se basent pas sur les mêmes metrics pour ressortir leurs résultats. Ex : Plus l'index db est faible plus les données sont bien classés.  Il évalue la similarité intra classe et la différence inter classes. 

Or que l'index silhouette lui va mesurer la distance entre chaque points de données avec le centre de gravité de la classe et vérifie que les points assigné à chaque centre de gravité sont bien les plus proches. 

Résultats normalisé : Silhouette & non normalisé : CCC et DB. Difficulté de plus pour comparer. 

Nous avons relançant kmeans avec la fonction nbclust juste avec les index cités au-dessus et stocker dans une variable le résultat de la meilleure partition avec 20 classes.

REM : *les résultats provenant du tableau ci-dessus sont renseigné à titre indicatif non comparatif*

Effectif des classes :

```{r}
kmeans.coilEff <- matrix(c(161,153,234,145,111,72,77,186,72,229),nrow = 1)
kmeans.coilEff
```

20 classes :

```{r}
kmeans.coilEff20 <-matrix(c(47,18,127,96,74,136,48,103,72,26,64,34,35,58,59,72,144,72,83,  72),nrow = 1)
kmeans.coilEff20
```


**Average**

Le vote majoritaire propose un regroupement en **14 classes**. 
Cependant selon les index Davies and Bouldin (db) et Sdbw proposent un clustering à 20 classes.

Effectif des classes :

```{r}
average.coilEff <- matrix(c(36,277,24,5,308,23,6,7,425,26,11,4,216,72),nrow = 1)
average.coilEff
```

20 classes :

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=FALSE,results='hide'}
average.coil20 = NbClust(data = coil.data, method = "average",min.nc = 15,max.nc = 20,index = c("sdbw","db"))
average.coil20
```


**Ward**

Le vote majoritaire propose un regroupement en **10 classes**. 
Cependant selon les index Silhouette, Cindex et CCC proposent un clustering à 20 classes.

Effectif des classes :

```{r}
ward.coilEff <- matrix(c(371,159,109,225,216,72,72,72,72,72),nrow = 1)
ward.coilEff
#
```

20 classes :

```{r}
ward.coilEff20 <- matrix(c(43,56,60,140,80,79,109,76,77,52,36,56,72,72,72,72,72,72,72,72),nrow = 1)
ward.coilEff20
```

**Single**

Le vote majoritaire propose un regroupement en **2 classes**. 
Aucun propose 20 clusters.

Effectif des classes :

```{r}
single.coilEff <- matrix(c(1438,2),nrow = 1)
single.coilEff
```

**Complete**

Le vote majoritaire propose un regroupement en **13 classes**. 
Cependant selon l'index Silhouette propose un clustering à 20 classes.

Effectif des classes :

```{r}
complete.coilEff <- matrix(c(39,186,212,48,67,5,162,4,365,36,24,4,288),nrow = 1)
complete.coilEff
```

20 classes :

```{r}
complete.coilEff20 <-matrix(c(30,100,60,41,152,39,5,158,4,7,4,86,9,365,28 ,36,24,4,102,186),nrow = 1)
complete.coilEff20
```


***

Jaffe data
----------

Obs : Les algorithmes sont lancés uniquement qu'en se basant sur l'index silhouette pour cause d'erreur avec d'autres index qui font planté la bonne éxecutions de ces algo. 

**Kmeans**

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
kmeans.jaffe = NbClust(jaffe$X, method = "kmeans",min.nc = 2,max.nc = 10,index = "silhouette")
```

Vote majoritaire propose un regroupement en **10 classes**.

Effectif des classes :

```{r}
kmeans.jaffeEff <- matrix(c(22,19,13,27,28,21,16,20,36,11),nrow = 1)
kmeans.jaffeEff
```

**Average**

Le vote majoritaire propose un regroupement en **9 classes**. 

Effectif des classes :

```{r}
average.jaffeEff <- matrix(c(98,29,19,3,19,2,27,3,13),nrow = 1)
average.jaffeEff
```

**Ward**

Le vote majoritaire propose un regroupement en **10 classes**.

Effectif des classes :

```{r}
ward.jaffeEff <- matrix(c(40,11,22,22,19,15,20,27,21,16),nrow = 1)
ward.jaffeEff
```

**Single**

Le vote majoritaire propose un regroupement en **7 classes**. 

Effectif des classes :

```{r}
single.jaffeEff <- matrix(c(146,19,3,2,27,3,13),nrow = 1)
single.jaffeEff
```

**Complete**

Le vote majoritaire propose un regroupement en **6 classes**.

Effectif des classes :

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=FALSE,results='hide'}
complete.jaffeEff <- matrix(c(101,48,19,2,27,16),nrow = 1)
complete.jaffeEff
```

***

Mnist data
----------

Obs : Les algorithmes sont lancés uniquement qu'en se basant sur l'index silhouette pour cause d'erreur avec d'autres index qui font planté la bonne éxecutions de ces algo. 

**Kmeans**

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
kmeans.mnist = NbClust(mnist.data, method = "kmeans",min.nc = 5,max.nc = 10)
```

Vote majoritaire propose un regroupement en **8 classes**.

Effectif des classes :

```{r}
kmeans.mnistEff <- matrix(c(297, 275, 454, 523, 628, 441, 543, 334 ),nrow = 1)
kmeans.mnistEff
```

**Average**

Le vote majoritaire propose un regroupement en ** 8 classes**. 

Effectif des classes :

```{r}
average.mnistEff <- matrix(c(311, 35, 3077, 41, 3, 26, 1,  1 ),nrow = 1)
average.mnistEff
```

**Ward**

Le vote majoritaire propose un regroupement en ** 10 classes**.

Effectif des classes :

```{r}
ward.mnistEff <- matrix(c(394, 332, 580, 319, 315, 552, 276, 178, 214, 335),nrow = 1)
ward.mnistEff
```

**Single**

Le vote majoritaire propose un regroupement en **8 classes**. 

Effectif des classes :

```{r}
single.mnistEff <- matrix(c(3488, 1, 1,  1, 1,  1, 1,  1 ),nrow = 1)
single.mnistEff
```

**Complete**

Le vote majoritaire propose un regroupement en **8 classes**.

Effectif des classes :

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=FALSE,results='hide'}
complete.mnistEff <- matrix(c( 468,  101,  85, 1929, 116,  469, 266, 61  ),nrow = 1)
complete.mnistEff
```



***

Mfeat data
----------

Obs : Les algorithmes sont lancés uniquement qu'en se basant sur l'index silhouette pour cause d'erreur avec d'autres index qui font planté la bonne éxecutions de ces algo. 

**Kmeans**

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
kmeans.mfeat = NbClust(mfeat.data, method = "kmeans",min.nc = 2,max.nc = 10,index = "silhouette")
```

Vote majoritaire propose un regroupement en **9 classes**.

Effectif des classes :

```{r}
kmeans.mfeatEff <- matrix(c(162, 183, 211, 230, 236, 372, 185, 188, 233 ),nrow = 1)
kmeans.mfeatEff
```

**Average**

Le vote majoritaire propose un regroupement en **9 classes**. 

Effectif des classes :

```{r}
average.mfeatEff <- matrix(c(365, 61,  45, 609, 162, 366, 1, 357, 33, 1),nrow = 1)
average.mfeatEff
```

**Ward**

Le vote majoritaire propose un regroupement en **9 classes**.

Effectif des classes :

```{r}
ward.mfeatEff <- matrix(c(406, 252, 219, 272, 204, 155, 176, 153, 163),nrow = 1)
ward.mfeatEff
```

**Single**

Le vote majoritaire propose un regroupement en **8 classes**. 

Effectif des classes :

```{r}
single.mfeatEff <- matrix(c(1993, 1, 1,  1,  1,  1,  1,  1 ),nrow = 1)
single.mfeatEff
```

**Complete**

Le vote majoritaire propose un regroupement en **10 classes**.

Effectif des classes :

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=FALSE,results='hide'}
complete.mfeatEff <- matrix(c(236, 64, 236, 591,  99,  73, 373, 122,  72, 134),nrow = 1)
complete.mfeatEff
```


***

## 5. Clustering à partir des deux premère composantes

*En bref* : L’approche HCPC (Hierarchical Clustering on Principal Components ou Classification Hiérarchique sur Composantes Principales) nous permet de combiner les trois méthodes standards utilisées dans les analyses de données multivariées c'est à dire les méthodes des composantes principales (ACP...); la classification ascendante hiérarchique et le partitionnement en k-moyennes.

*Rem* : Dans cette partie nous avons paramétré la fonction HCPC à -1 afin qu'il nous propose pour lui le meilleure découpage du dendogramme. Mais nous avons aussi initialisé au bon nombre de classes afin de voir pouvoir comparer par la suite les effectifs.

**Coil data**

Mode automatique : HCPC propose 3 clusters distincts

```{r, eval=FALSE, message=FALSE, warning=FALSE, include=TRUE, results='hide',echo='FALSE'}
hcpc.coil <- HCPC(pca.coil,nb.clust = -1,graph = TRUE)
```

Visualisation du dendrogramme généré avec prise en compte des clusters proposé par HCPC

```{r, eval=FALSE, message=FALSE, warning=FALSE, include=TRUE, results='hide',echo='FALSE'}
fviz_dend(hcpcAuto.coil,
          palette = "jco",               # Palette de couleur 
          rect = TRUE, rect_fill = TRUE, # Rectangle autour des groupes
          rect_border = "jco"           # Couleur du rectangle
          )
```

![](Coildendo3clus.png)

Visualisation des individus sur un plan factoriel regroupé en fonction des classes par couleurs avec prise en compte des clusters proposé par HCPC

```{r, eval=FALSE, message=FALSE, warning=FALSE, include=TRUE, results='hide',echo='FALSE'}
fviz_cluster(hcpc.coil,
             repel = TRUE,            # Evite le chevauchement des textes
             show.clust.cent = TRUE, # Montre le centre des clusters
             palette = "jco",         # Palette de couleurs,
             ggtheme = theme_minimal(),
             main = "Factor map"
             )
```

![](factorcoil3clus.png)

Init avec 20 clusters

```{r, eval=FALSE, message=FALSE, warning=FALSE, include=TRUE, results='hide',echo='FALSE'}
hcpc20.coil <- HCPC(pca.coil,nb.clust = 20,graph = TRUE)
```

Visualisation du dendrogramme généré avec prise en compte des clusters proposé par HCPC

```{r, eval=FALSE, message=FALSE, warning=FALSE, include=TRUE, results='hide',echo='FALSE'}
fviz_dend(hcpc20.coil,
          palette = "jco",               # Palette de couleur 
          rect = TRUE, rect_fill = TRUE, # Rectangle autour des groupes
          rect_border = "jco"           # Couleur du rectangle
          )
```

![](Hcpc20.png)

Visualisation des individus sur un plan factoriel regroupé en fonction des classes par couleurs avec prise en compte des clusters proposé par HCPC

```{r, eval=FALSE, message=FALSE, warning=FALSE, include=TRUE, results='hide',echo='FALSE'}
fviz_cluster(hcpc20.coil,
             repel = TRUE,            # Evite le chevauchement des textes
             show.clust.cent = TRUE, # Montre le centre des clusters
             palette = "jco",         # Palette de couleurs
             ggtheme = theme_minimal(),
             main = "Factor map"
             )
```

![](Illisible.png)

***

**Jaffe data** 

Mode automatique HCPC nous propose 4 clusters distincts 

Init avec 10 classes

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
hcpc10.Jaffe <- HCPC(pca.jaffe,nb.clust = 10,graph = TRUE)
```

Visualisation du dendrogramme généré avec prise en compte des clusters proposé par HCPC

```{r, eval=FALSE, message=FALSE, warning=FALSE, include=TRUE, results='hide',echo='FALSE'}
fviz_dend(hcpc10.Jaffe,
          palette = "jco",               # Palette de couleur 
          rect = TRUE, rect_fill = TRUE, # Rectangle autour des groupes
          rect_border = "jco"           # Couleur du rectangle
          )
```

![](dendoHCPCAuto_Jaffe.png)

Visualisation des individus sur un plan factoriel regroupé en fonction des classes par couleurs avec prise en compte des clusters proposé par HCPC

```{r, eval=FALSE, message=FALSE, warning=FALSE, include=TRUE, results='hide',echo='FALSE'}
fviz_cluster(hcpc10.Jaffe,
             repel = TRUE,            # Evite le chevauchement des textes
             show.clust.cent = TRUE, # Montre le centre des clusters
             palette = "jco",         # Palette de couleurs, voir ?ggpubr::ggpar
             ggtheme = theme_minimal(),
             main = "Factor map"
             )
```

![](jaffe10hcpc.png)

***

**Mfeat data**

Mode automatique HCPC nous propose 4 clusters distincts 

Init avec 10 classes

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
hcpc.mfeat <- HCPC(pca.mfeat,nb.clust = 10,graph = TRUE)
```

Visualisation du dendrogramme généré avec prise en compte des clusters proposé par HCPC

```{r, eval=FALSE, message=FALSE, warning=FALSE, include=TRUE, results='hide',echo='FALSE'}
fviz_dend(hcpc.mfeat,
          palette = "jco",               # Palette de couleur 
          rect = TRUE, rect_fill = TRUE, # Rectangle autour des groupes
          rect_border = "jco"           # Couleur du rectangle
          )
```

![](dendohcpc_mfeat.png)

Visualisation des individus sur un plan factoriel regroupé en fonction des classes par couleurs avec prise en compte des clusters proposé par HCPC

```{r, eval=FALSE, message=FALSE, warning=FALSE, include=TRUE, results='hide',echo='FALSE'}
fviz_cluster(hcpc.mfeat,
             repel = TRUE,            # Evite le chevauchement des textes
             show.clust.cent = TRUE, # Montre le centre des clusters
             palette = "jco",         # Palette de couleurs, voir ?ggpubr::ggpar
             ggtheme = theme_minimal(),
             main = "Factor map"
             )
```

![](hcpcAuto_mfeat.png)

***

**Mnist data**

Mode automatique HCPC nous propose 3 clusters distincts 

Init avec 10 classes

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
hcpc.mnist <- HCPC(pca.mnist,nb.clust = 10,graph = TRUE)
```

Visualisation du dendrogramme généré avec prise en compte des clusters proposé par HCPC

```{r, eval=FALSE, message=FALSE, warning=FALSE, include=TRUE, results='hide',echo='FALSE'}
fviz_dend(hcpc.mnist,
          palette = "jco",               # Palette de couleur 
          rect = TRUE, rect_fill = TRUE, # Rectangle autour des groupes
          rect_border = "jco"           # Couleur du rectangle
          )
```

![](dendhcpc_mnist.png)

Visualisation des individus sur un plan factoriel regroupé en fonction des classes par couleurs avec prise en compte des clusters proposé par HCPC

```{r, eval=FALSE, message=FALSE, warning=FALSE, include=TRUE, results='hide',echo='FALSE'}
fviz_cluster(hcpc.mnist,
             repel = TRUE,            # Evite le chevauchement des textes
             show.clust.cent = TRUE, # Montre le centre des clusters
             palette = "jco",         # Palette de couleurs, voir ?ggpubr::ggpar
             ggtheme = theme_minimal(),
             main = "Factor map"
             )
```

![](hcpcauto_mnist.png)

## 6. Spectral clustering

**En bref **: le Spectral Clustering c’est trois étapes :Construire une matrice qui représente les affinités entre les individus; Projeter les individus sur un plan en fonction de leurs affinités et Appliquer une méthode classique de clustering (le plus souvent une K-means) sur ces nouvelles coordonnées.

Pour réaliser notre spectral clustering nous utilisons le package kernlab qui contiens la fonction specc() qui est le kmeans spectrale

**Coil data**

Nous devons initialisé notre algorithme par un nombre de clusters souhaité. Nous allons directement l'initialisé aux nombres de classes adéquat c'est à dire 20 pour le jeu de données Coil. Nous allons voir en terme d'effectif s'il arrive à classer les individus au mieux donc plus proche de la réalité.

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
n.cluster.coil = 20
specc.coil = specc(x = coil.data, n.cluster.coil)
```

Effectif des classes suite au spectrale

```{r}
specc.CoilEff <- matrix(c(68,72,105,72,76,72,41,18,6,162,32,72,103,90,62,27,27,214,75,46),nrow = 1)
specc.CoilEff
```

***

**Jaffe data**

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
n.cluster.jaffe = 10
specc.jaffe = specc(x = jaffe.data, n.cluster.jaffe)
```

Effectif des classes suite au spectrale

```{r}
specc.jaffeEff <- matrix(c(17,14,3,4,77,13,5,32,45,3),nrow = 1)
specc.jaffeEff
```

***

**Mfeat data**

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
n.cluster.mfeat = 10
specc.mfeat = specc(x = mfeat.data, n.cluster.mfeat)
```

Effectif des classes suite au spectrale

```{r}
specc.mfeatEff <- matrix(c(16, 45, 188, 395, 203, 160, 211, 212, 190, 380),nrow = 1)
specc.mfeatEff
```

***

**Mnist data** 

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
n.cluster.mnist = 10
specc.mnist = specc(x = mnist.data, n.cluster.mnist)
```

Effectif des classes suite au spectrale

```{r}
specc.mnistEff <- matrix(c(573, 609,  77, 312, 304, 440, 315, 112, 417, 336),nrow = 1)
specc.mnistEff
```


## 7. Proposition d'un nombre de classes

Pour choisir le nombre de classes nous allons nous basé sur ce que nous avons réalisé au préalable.

Nous avons réalisé des méthodes qu'on pourrait qualifier d'automatique c'est à dire qu'on a laissé les algorithmes nous proposer selon leurs calculs un nombre de clusters ainsi qu'une répartition de la population. (Nbclust et HCPC). Puis nous avons initialisé par nous même le nombre de cluster avec le spectrale.

**Coil data**

Proposition : 20 classes 

**Jaffe data** 

Proposition : 10 classes

**Mfeat data** 

Proposition : 10

**Mnist data** 

Proposition : 10

## 8. Modèle de mélange

**En bref** : Dans les modèles de mélanges, fréquemment utilisés en classification automatique, on considère qu'un échantillon de données suit, non pas une loi de probabilité usuelle, mais une loi dont la fonction de densité est une densité mélange. N'importe quelle loi peut être utilisée, la plus courante est la loi normale dont la fonction de densité est une gaussienne. On parle alors de mélange gaussien

**Coil data**

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
EM.coil <- mixmodCluster(data.frame(pca.coil$ind), 2:21,dataType = "quantitative",criterion = "BIC",strategy = new("Strategy",algo = "EM"))
```

Effectif des classes 

```{r}
em.coilEff <- matrix(c(72,160,72,178,33,99,80,37,49,60,66,72,61,21,72,72,71,100,42,23),nrow = 1)
em.coilEff
```

Mclust

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
mclust.coil = Mclust(coil.data,G = 2:20)
```

```{r}
mclust.coilEff <- matrix(c(2,19,22,43,10,15,19,9,47,27),nrow = 1)
mclust.coilEff
```


***

**Jaffe data** 

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
EM.jaffe <- mixmodCluster(data.frame(pca.jaffe$ind), 2:10,dataType = "quantitative",criterion = "BIC",strategy = new("Strategy",algo = "EM"))
```

Effectif des classes 

```{r}
em.jaffeEff <- matrix(c(2,19,22,43,10,15,19,9,47,27),nrow = 1)
em.jaffeEff
```

Mclust

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
mclust.jaffe = Mclust(jaffe.data,G = 2:10)
```

Effectif des classes 

```{r}
mclust.jaffeEff <- matrix(c(24,22,22,19,22,20,20,27,21,16),nrow = 1)
mclust.jaffeEff
```

***

**Mfeat data** 

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
all <- mixmodGaussianModel()
EM.mfeat <- mixmodCluster(as.data.frame(mfeat.data), models = all, strategy = new("Strategy",algo = "EM"), nbCluster = 10)
View(EM.mfeat@bestResult@partition)
```


```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
mclust.mfeat = Mclust(mfeat.data)
```

***

**Mnist data**

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
all <- mixmodGaussianModel()
EM.jaffe <- mixmodCluster(as.data.frame(jaffe.data), models = all, strategy = new("Strategy",algo = "EM"), nbCluster = 10)
View(EM.jaffe@bestResult@partition)
```


```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
mclust.jaffe = Mclust(jaffe.data)
```

## 9. MclustDR

**En bref** : La fonction MclustDR est une méthode de réduction de dimension qui permet de visualiser la structure de classification ou de classification obtenue à partir d'un mélange fini de densités gaussiennes.

**Coil data**

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
mclustdr.coil <- MclustDR(mclust.coil)
```

Effectif des classes 

```{r}
mclustdr.coilEff <- matrix(c(38,29,29,21,20,19,19,17,17,4),nrow = 1)
mclustdr.coilEff
```

***

**Jaffe data** 

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
mclustdr.jaffe <- MclustDR(mclust.jaffe)
```

Effectif des classes 

```{r}
mclustdr.jaffeEff <- matrix(c(24,22,22,19,22,20,20,27,21,16),nrow = 1)
mclustdr.jaffeEff
```

## 10. Etudes comparatives des performances

Dans cette partie nous avons utilisé la méthode de matrice de confusion pour avoir une idée des points bien classés ainsi que les mal classés en les comparants aux différentes réelles classes respectives.

De plus nous utilisons une fonction external_validation() provenant du package ClusteR qui permet d'avoir une palette de mesures de performances de clustering. Nous afficherons la NMI, specificity (false negative rate), sensitivity (True positive rate), precision, recall et F-Mesure. Nous pouvons afficher d'autres mesures de performances mais selon nos recherches ainsi que leurs significations ils s'agit la des mesures les plus courantes pour se fier à la repartitions des points de nos cluster en comparaison des vrais labels. De plus ce sont ces mesures que nous avons pu aborder dans différents cours.


**Coil data** 

>Kmeans

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
kmeansPartition.coil <- kmeans.coil20$Best.partition
kmeans.coilMatConf <- table(kmeans = kmeansPartition.coil,label = coil.label)
kmeansscore = external_validation(as.vector(coil.label),as.numeric(kmeansPartition.coil), method = "nmi", summary_stats = T)
```

Mesure de performances

```{r}
kmeans.coilScore <- data.frame(specificity=0.9702,sensitivity=0.6543,precision=0.5323,recall=0.6543,NMI=0.765,entropy=0.2118,purity=0.6438,row.names = "score")
kmeans.coilScore
```


>Average

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
averagePartition.coil <- average.coil$Best.partition
table(average = averagePartition.coil,label = coil.label)
averagescore = external_validation(as.vector(coil.label),as.numeric(averagePartition.coil), method = "nmi", summary_stats = T)
```

Mesure de performances

```{r}
average.coilScore <- data.frame(specificity=0.8373,sensitivity=0.835,precision=0.2103,recall=0.835,NMI=0.6358,entropy=0.106,purity=0.3222,row.names = "score")
average.coilScore
```


>Ward


```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
wardPartition.coil <- ward.coil20$Best.partition
table(ward = wardPartition.coil,label = coil.label)
wardscore = external_validation(as.vector(coil.label),as.numeric(wardPartition.coil), method = "nmi", summary_stats = T)
```

Mesure de performances

```{r}
ward.coilScore <- data.frame(specificity=0.9818,sensitivity=0.7433,precision=0.6811,recall=0.7433,NMI=0.6359,entropy=0.1469,purity=0.7771,row.names = "score")
ward.coilScore
```


>Complete


```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
completePartition.coil <- complete.coil20$Best.partition
table(complete = completePartition.coil,label = coil.label)
res = external_validation(as.vector(coil.label),as.numeric(completePartition.coil), method = "nmi", summary_stats = T)
```

Mesure de performances

```{r}
complete.coilScore <- data.frame(specificity=0.9076,sensitivity=0.6931,precision=0.2803,recall=0.6931,NMI=0.6675,entropy=0.2019,purity=0.4451,row.names = "score")
complete.coilScore
```



>HCPC

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
hcpcPartition.coil <- hcpc20.coil$data.clust$clust
table(hcpc = hcpcPartition.coil,label = coil.label)
res = external_validation(as.vector(coil.label),as.numeric(hcpcPartition.coil), method = "nmi", summary_stats = T)
```

Mesure de performances

```{r}
hcpc.coilScore <- data.frame(specificity=0.9618,sensitivity=0.6202,precision=0.4574,recall=0.6202,NMI=0.7254,entropy=0.2432,purity=0.5944,row.names = "score")
hcpc.coilScore
```


>Spectrale

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
speccPartition.coil <- specc.coil@.Data
table(specc = speccPartition.coil,label = coil.label)
res = external_validation(as.vector(coil.label),as.numeric(speccPartition.coil), method = "nmi", summary_stats = T)
```

Mesure de performances

```{r}
specc.coilScore <- data.frame(specificity=0.9665,sensitivity=0.7984,precision=0.5531,recall=0.7984,NMI=0.8387,entropy=0.1219,purity=0.7326,row.names = "score")
specc.coilScore
```


>EM

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
emPartition.coil <- EM.coil@bestResult@partition
table(em = emPartition.coil,label = coil.label)
res = external_validation(as.vector(coil.label),as.numeric(emPartition.coil), method = "nmi", summary_stats = T)
```

Mesure de performances

```{r}
em.coilScore <- data.frame(specificity=0.9747,sensitivity=0.6298,precision=0.5636,recall=0.6298,NMI=0.7696,entropy=0.2218,purity=0.7083,row.names = "score")
em.coilScore
```


>Mclust

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
MclustPartition.coil <- mclust.coil$classification
table(Mclust = MclustPartition.coil,label = coil.label)
```

>MclustDR

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
MclustDRpartition.coil <- MclustDR.coil
table(MclustDR = MclustDRPartition.coil,label = coil.label)
```

***

**Jaffe data** 

>Kmeans

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
kmeansPartition.jaffe <- kmeans.jaffe$Best.partition
table(kmeans = kmeansPartition.jaffe,label = jaffe.label)
res = external_validation(as.vector(jaffe.label),as.numeric(kmeansPartition.jaffe), method = "nmi", summary_stats = T)
```

Mesure de performances

```{r}
kmeans.jaffeScore <- data.frame(specificity=0.9713,sensitivity=0.8444,precision=0.7577,recall=0.8444,NMI=0.8945,entropy=0.0925,purity=0.8685,row.names = "score")
kmeans.jaffeScore
```


>Ward

7 classes bien trouvées

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
wardPartition.jaffe <- ward.jaffe$Best.partition
table(ward = wardPartition.jaffe,label = jaffe.label)
res = external_validation(as.vector(jaffe.label),as.numeric(wardPartition.jaffe), method = "nmi", summary_stats = T)
```

Mesure de performances

```{r}
ward.jaffeScore <- data.frame(specificity=0.9699,sensitivity=0.8444,precision=0.7484,recall=0.8444,NMI=0.8939,entropy=0.0925,purity=0.8826,row.names = "score")
ward.jaffeScore
```


>Complete


```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
completePartition.jaffe <- complete.jaffe$Best.partition
table(complete = completePartition.jaffe,label = jaffe.label)
res = external_validation(as.vector(jaffe.label),as.numeric(completePartition.jaffe), method = "nmi", summary_stats = T)
```

Mesure de performances

```{r}
complete.jaffeScore <- data.frame(specificity=0.7559,sensitivity=0.8486,precision=0.2695,recall=0.8486,NMI=0.6381,entropy=0.0966,purity=0.4789,row.names = "score")
complete.jaffeScore
```


>HCPC

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
hcpcPartition.jaffe <- hcpc10.Jaffe$data.clust$clust
table(hcpc = hcpcPartition.jaffe,label = jaffe.label)
res = external_validation(as.vector(jaffe.label),as.numeric(hcpcPartition.jaffe), method = "nmi", summary_stats = T)
```

Mesure de performances

```{r}
hcpc.jaffeScore <- data.frame(specificity=0.9525,sensitivity=0.7608,precision=0.6295,recall=0.7608,NMI=0.8229,entropy=0.1509,purity=0.7559,row.names = "score")
hcpc.jaffeScore
```


>Spectrale

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
speccPartition.jaffe <- specc.jaffe@.Data
table(specc = speccPartition.jaffe,label = jaffe.label)
res = external_validation(as.vector(jaffe.label),as.numeric(speccPartition.jaffe), method = "nmi", summary_stats = T)
```

Mesure de performances

```{r}
specc.jaffeScore <- data.frame(specificity=0.8467,sensitivity=0.7433,precision=0.3397,recall=0.7433,NMI=0.6955,entropy=0.1666,purity=0.5681,row.names = "score")
specc.jaffeScore
```


>EM

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
emPartition.jaffe <- EM.jaffe@bestResult@partition
table(em = emPartition.jaffe,label = jaffe.label)
res = external_validation(as.vector(jaffe.label),as.numeric(emPartition.jaffe), method = "nmi", summary_stats = T)
```

Mesure de performances

```{r}
em.jaffeScore <- data.frame(specificity=0.9294,sensitivity=0.7645,precision=0.5345,recall=0.7645,NMI=0.7946,entropy=0.1533,purity=0.6901,row.names = "score")
em.jaffeScore
```


>Mclust

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
MclustPartition.jaffe <- mclust.jaffe$classification
table(Mclust = MclustPartition.jaffe,label = jaffe.label)
res = external_validation(as.vector(jaffe.label),as.numeric(MclustPartition.jaffe), method = "nmi", summary_stats = T)
```

Mesure de performances

```{r}
mclust.jaffeScore <- data.frame(specificity=0.9658,sensitivity=0.9377,precision=0.7442,recall=0.9377,NMI=0.9205,entropy=0.0426,purity=0.8638,row.names = "score")
mclust.jaffeScore
```


>MclustDR

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
MclustDRpartition.jaffe <- mclustdr.jaffe$class
table(MclustDR = MclustDRpartition.jaffe,label = jaffe.label)
res = external_validation(as.vector(jaffe.label),as.numeric(MclustDRpartition.jaffe), method = "nmi", summary_stats = T)
```

Mesure de performances

```{r}
mclustdr.jaffeScore <- data.frame(specificity=0.9658,sensitivity=0.9377,precision=0.7442,recall=0.9377,NMI=0.9205,entropy=0.0426,purity=0.8638,row.names = "score")
mclustdr.jaffeScore
```


***


**Mfeat data** 

>Kmeans

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
kmeansPartition.mfeat <- kmeans.mfeat$Best.partition
kmeans.mfeat <- table(kmeans = kmeansPartition.mfeat,label = mfeat.label)
kmeansscore = external_validation(as.vector(mfeat.label),as.numeric(kmeansPartition.mfeat), method = "nmi", summary_stats = T)
```

Mesure de performances

```{r}
kmeans.mfeatScore <- data.frame(specificity=0.9492,sensitivity=0.7288,precision=0.6131,recall=0.7288,NMI=0.724,entropy=0.2383,purity=0.7345,row.names = "score")
kmeans.mfeatScore
```


>Average

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
averagePartition.mfeat <- average.mfeat$Best.partition
table(average = averagePartition.mfeat,label = mfeat.label)
averagescore = external_validation(as.vector(mfeat.label),as.numeric(averagePartition.mfeat), method = "nmi", summary_stats = T)
```

Mesure de performances

```{r}
average.mfeatScore <- data.frame(specificity=0.8674,sensitivity=0.8021,precision=0.4007,recall=0.8021,NMI=0.6625,entropy=0.1804,purity=0.4885,row.names = "score")
average.mfeatScore
```


>Ward


```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
wardPartition.mfeat <- ward.mfeat$Best.partition
table(ward = wardPartition.mfeat,label = mfeat.label)
wardscore = external_validation(as.vector(mfeat.label),as.numeric(wardPartition.mfeat), method = "nmi", summary_stats = T)
```

Mesure de performances

```{r}
ward.mfeatScore <- data.frame(specificity=0.9485,sensitivity=0.7777,precision=0.6255,recall=0.7777,NMI=0.764,entropy=0.1935,purity=0.781,row.names = "score")
ward.mfeatScore
```


>Complete


```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
completePartition.mfeat <- complete.mfeat$Best.partition
table(complete = completePartition.mfeat,label = mfeat.label)
res = external_validation(as.vector(mfeat.label),as.numeric(completePartition.mfeat), method = "nmi", summary_stats = T)
```

Mesure de performances

```{r}
complete.mfeatScore <- data.frame(specificity=0.9076,sensitivity=0.6931,precision=0.2803,recall=0.6931,NMI=0.6675,entropy=0.2019,purity=0.4451,row.names = "score")
complete.mfeatScore
```



>HCPC

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
hcpcPartition.mfeat <- hcpc20.mfeat$data.clust$clust
table(hcpc = hcpcPartition.mfeat,label = mfeat.label)
res = external_validation(as.vector(mfeat.label),as.numeric(hcpcPartition.mfeat), method = "nmi", summary_stats = T)
```

Mesure de performances

```{r}
hcpc.mfeatScore <- data.frame(specificity=0.9618,sensitivity=0.6202,precision=0.4574,recall=0.6202,NMI=0.7254,entropy=0.2432,purity=0.5944,row.names = "score")
hcpc.mfeatScore
```


>Spectrale

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
speccPartition.mfeat <- specc.mfeat@.Data
table(specc = speccPartition.mfeat,label = mfeat.label)
res = external_validation(as.vector(mfeat.label),as.numeric(speccPartition.mfeat), method = "nmi", summary_stats = T)
```

Mesure de performances

```{r}
specc.mfeatScore <- data.frame(specificity=0.9665,sensitivity=0.7984,precision=0.5531,recall=0.7984,NMI=0.8387,entropy=0.1219,purity=0.7326,row.names = "score")
specc.mfeatScore
```


>EM

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
emPartition.mfeat <- EM.mfeat@bestResult@partition
table(em = emPartition.mfeat,label = mfeat.label)
res = external_validation(as.vector(mfeat.label),as.numeric(emPartition.mfeat), method = "nmi", summary_stats = T)
```

Mesure de performances

```{r}
em.mfeatScore <- data.frame(specificity=0.9747,sensitivity=0.6298,precision=0.5636,recall=0.6298,NMI=0.7696,entropy=0.2218,purity=0.7083,row.names = "score")
em.mfeatScore
```


>Mclust

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
MclustPartition.mfeat <- mclust.mfeat$classification
table(Mclust = MclustPartition.mfeat,label = mfeat.label)
```

>MclustDR

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
MclustDRpartition.mfeat <- MclustDR.mfeat
table(MclustDR = MclustDRPartition.mfeat,label = mfeat.label)
```

***


**Mnist data** 

>Kmeans

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
kmeansPartition.mnist <- kmeans.mnist20$Best.partition
kmeans.mnistMatConf <- table(kmeans = kmeansPartition.mnist,label = mnist.label)
kmeansscore = external_validation(as.vector(mnist.label),as.numeric(kmeansPartition.mnist), method = "nmi", summary_stats = T)
```

Mesure de performances

```{r}
kmeans.mnistScore <- data.frame(specificity=0.9702,sensitivity=0.6543,precision=0.5323,recall=0.6543,NMI=0.765,entropy=0.2118,purity=0.6438,row.names = "score")
kmeans.mnistScore
```


>Average

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
averagePartition.mnist <- average.mnist$Best.partition
table(average = averagePartition.mnist,label = mnist.label)
averagescore = external_validation(as.vector(mnist.label),as.numeric(averagePartition.mnist), method = "nmi", summary_stats = T)
```

Mesure de performances

```{r}
average.mnistScore <- data.frame(specificity=0.8373,sensitivity=0.835,precision=0.2103,recall=0.835,NMI=0.6358,entropy=0.106,purity=0.3222,row.names = "score")
average.mnistScore
```


>Ward


```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
wardPartition.mnist <- ward.mnist20$Best.partition
table(ward = wardPartition.mnist,label = mnist.label)
wardscore = external_validation(as.vector(mnist.label),as.numeric(wardPartition.mnist), method = "nmi", summary_stats = T)
```

Mesure de performances

```{r}
ward.mnistScore <- data.frame(specificity=0.9818,sensitivity=0.7433,precision=0.6811,recall=0.7433,NMI=0.6359,entropy=0.1469,purity=0.7771,row.names = "score")
ward.mnistScore
```


>Complete


```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
completePartition.mnist <- complete.mnist20$Best.partition
table(complete = completePartition.mnist,label = mnist.label)
res = external_validation(as.vector(mnist.label),as.numeric(completePartition.mnist), method = "nmi", summary_stats = T)
```

Mesure de performances

```{r}
complete.mnistScore <- data.frame(specificity=0.9076,sensitivity=0.6931,precision=0.2803,recall=0.6931,NMI=0.6675,entropy=0.2019,purity=0.4451,row.names = "score")
complete.mnistScore
```



>HCPC

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
hcpcPartition.mnist <- hcpc20.mnist$data.clust$clust
table(hcpc = hcpcPartition.mnist,label = mnist.label)
res = external_validation(as.vector(mnist.label),as.numeric(hcpcPartition.mnist), method = "nmi", summary_stats = T)
```

Mesure de performances

```{r}
hcpc.mnistScore <- data.frame(specificity=0.9618,sensitivity=0.6202,precision=0.4574,recall=0.6202,NMI=0.7254,entropy=0.2432,purity=0.5944,row.names = "score")
hcpc.mnistScore
```


>Spectrale

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
speccPartition.mnist <- specc.mnist@.Data
table(specc = speccPartition.mnist,label = mnist.label)
res = external_validation(as.vector(mnist.label),as.numeric(speccPartition.mnist), method = "nmi", summary_stats = T)
```

Mesure de performances

```{r}
specc.mnistScore <- data.frame(specificity=0.9665,sensitivity=0.7984,precision=0.5531,recall=0.7984,NMI=0.8387,entropy=0.1219,purity=0.7326,row.names = "score")
specc.mnistScore
```


>EM

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
emPartition.mnist <- EM.mnist@bestResult@partition
table(em = emPartition.mnist,label = mnist.label)
res = external_validation(as.vector(mnist.label),as.numeric(emPartition.mnist), method = "nmi", summary_stats = T)
```

Mesure de performances

```{r}
em.mnistScore <- data.frame(specificity=0.9747,sensitivity=0.6298,precision=0.5636,recall=0.6298,NMI=0.7696,entropy=0.2218,purity=0.7083,row.names = "score")
em.mnistScore
```


>Mclust

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
MclustPartition.mnist <- mclust.mnist$classification
table(Mclust = MclustPartition.mnist,label = mnist.label)
```

>MclustDR

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
MclustDRpartition.mnist <- MclustDR.mnist
table(MclustDR = MclustDRPartition.mnist,label = mnist.label)
```

***


## 11. Cluspa

**Coil data** 

Obs : 

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
cluspca.coil <- cluspca(coil.data,method = c("RKM","FKM"),nclus = 10,ndim = 2,alpha = 1)
table(cluspca.coil$cluster)
```

Effectif des classes 

```{r}
cluspca.coilEff <- matrix(c(38,29,29,21,20,19,19,17,17,4),nrow = 1)
cluspca.coilEff
```

***

**Jaffe data** 

Obs : 

```{r,eval=FALSE, message=FALSE, warning=FALSE, include=TRUE,results='hide'}
cluspca.jaffe <- cluspca(jaffe.data,method = c("RKM","FKM"),nclus = 10,ndim = 2,alpha = 1)
```

Effectif des classes 

```{r}
cluspca.jaffeEff <- matrix(c(38,29,29,21,20,19,19,17,17,4),nrow = 1)
cluspca.jaffeEff
```

***


