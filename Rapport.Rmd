---
title: "Rapport"
output:
  pdf_document: default
  html_document: default
---

## Plan

Partie I : Commun à toutes les données

1. Introduction
2. Exploration des données

Partie II : Spécifique à chaque jeu de données

3. Analyse en composante principale
4. Clustering avec package Nbclust
5. Clustering à partir des deux premère composantes
6. Spectral clustering
7. Proposition d'un nombre de classes
8. Modèle de mélange
9. MclustDR
10. Etudes comparatives des performances
11. Cluspa

***
> Librairies

```{r, LibraryCheck, message=FALSE, warning=FALSE}
library(R.matlab)
library(FactoMineR)
library(NbClust)
```

REM

## 1. Introduction 

Nous avons pour but dans ce projet de mettre en corrélation nos compétences acquises dans le cours de réduction de dimension ainsi qu'en modèle de mélange. En appliquant des algotithmes sur différents jeu de données qui ont pour point commun être des bases de données d'images. Une fois ces algorithmes lancé nous devions faire un travail d'analyse, d'interprêtations et de comparaison pour trouver selon nous ce qui nous semble être les solutions les plus cohérentes et meilleures. 

Description des jeu de données : 
------------------------------

Columbia University Image Library (Coil20 Processed) : Base de données contenant 1440 images de 20 objets différents pris sous différents angles. Ce jeu de données est composé de 1440 observations et 1024 variables

Japanese Female Facial Expression (JAFFE) : Base de données contenant 213 photos de 10 femmes représentant 6 émotions (+1 neutre). Ce jeu de données est composé de 213 observations et 676 variables.

Multi-Feature digit (MFEAT1) : Cet ensemble de données est constitué de caractéristiques de chiffres manuscrits (0 à 9)
extrait d'une collection de cartes d'utilité néerlandaises. 200 motifs par
classe (pour un total de 2 000 modèles) ont été numérisés en binaire. Ce jeu données est composé de 2000 observations et 240 variables.

Mixed National Institute of Standards and Technology (MNIST) : La base MNIST est devenu un test standard1. Elle regroupe 60.000 images d'apprentissage et 10.000 images de test, issues d'une base de données antérieure, appelée simplement NIST1. Ce sont des images en noir et blanc, normalisées centrées de 28 pixels de côté. Ce jeu de données (réduit) est composé de 3495 observations et 784 variables.

***

## 2. Chargement des données

Chargement des données
----------------------

```{r,results='hide',message=FALSE,warning=FALSE}
coil <- readMat("data/DATA_MATLAB - Projet-master-MLDS/COIL20_1440n_1024d_20c.mat")
jaffe <- readMat("data/DATA_MATLAB - Projet-master-MLDS/jaffe.mat")
mnist <- readMat("data/DATA_MATLAB - Projet-master-MLDS/MNIST5.mat")
mfeat <- readMat("data/DATA_MATLAB - Projet-master-MLDS/MFEAT1.mat")
```

Séparation en data et label
-------------------------

Chaque datasets est au format .mat ils contiennent tous une colonne "Y" correspondants à la classe ou variable à expliquer ainsi que des varibles explicatives ou features "X".

Nous les avons assignées dans des différentes variables pour plus de faciliter et de clarté dans notre code.

```{r}
coil.data <- coil$X
coil.label <- coil$y

jaffe.data <- jaffe$X
jaffe.label <- jaffe$y

mfeat.data <- mfeat$X
mfeat.label <- mfeat$y

mnist.data <- mnist$X
mnist.label <- mnist$y
```


## 3. Analyse en composante principale

Dans cette étude de l'ACP nous allons plus nous intéresser aux individus. Car pour la suite ce qui nous intérèsse est le partitionnement de ceux-là.

**Coil data**

```{r,results='hide',message=FALSE,warning=FALSE}
pca.coil <- PCA(coil.data)
```

Obs : ci-dessous on retrouve une visualisation du plan d'individus factorielle issu de l'ACP.(Le cercle de corrélation des variables n'est pas affiché du fait que l'on peux pas distinguer des variables pertinentes ou non dans notre analyse)


![](ACP_Coil.png)

```{r,results='hide',message=FALSE,warning=FALSE}
fviz_eig(pca.coil, addlabels = TRUE, ylim = c(0, 50),main = "Graphique des valeurs propres cumulées par dimensions")
```

En se basant sur la méthode du coude nous nous assurons bien que les deux composantes (1 et 2) sont les plus répresentative de notre jeu de données de base ainsi notre nuage de point sera le plus représentatif. Mais on remarque aussi qu'en terme de variance expliquée pour les deux dimensions on se retrouve qu'à environ 35% ce qui est faible.

![](coudeMethode.png)

De plus on peux s'intéresser à la qualité de représentation du nuage d'individu. Un point est dit bien représenté sur un axe ou un plan factoriel si il est proche de sa projection sur l’axe ou le plan. S’il est éloigné, on dit qu’il est mal représenté. Indicateur =angle formé entre le point et sa projection sur l’axe. Lorsque l’angle est proche de 0, c'est-à-dire que le cosinus est proche de 1, l’individu est bien représenté. Dans le cas inverse, l’angle est proche de 90° et le cosinus est proche de 0

Cependant au vu du nombre d'observations que l'on à afficher le graphe du cos2 par individu ne serait pas très pertinents car graphiquement parlant il ne serait pas possible de définir quel individu à une meilleure qualité de représentation qu'un autre. De même que pour la contributions des individus au composantes 1 et 2. 

***

**Jaffe data**

```{r,results='hide',message=FALSE,warning=FALSE}
pca.jaffe <- PCA(jaffe.data)
```

Obs : Ci-dessous on retrouve une visualisation du plan d'individus factorielle issu de l'ACP.(Le cercle de corrélation des variables n'est pas affiché du fait que l'on peux pas distinguer des variables pertinentes ou non dans notre analyse)

De même que pour l'ACP du jeu de données Coil on remarque une répartition des individu très distincte ce qui dans un premier temps peut nous renseigner sur le fait que les individus ne sont pas identiques ou colporte la même informations (présence de doublons)

![](ACP_jaffe.png)

Méthode du coude : 
Dim 1 = 31,4% variance expliquée (valeurs propres)
Dim 2 = 15% variance expliquée (valeurs propres)

```{r,results='hide',message=FALSE,warning=FALSE}
fviz_eig(pca.jaffe, addlabels = TRUE, ylim = c(0, 50),main = "Graphique des valeurs propres cumulées par dimensions")
```

![](coude_jaffe.png)

Qualité de représentation : 

```{r}
fviz_pca_ind (pca.jaffe, col.ind = "cos2",
              gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
              repel = TRUE # Évite le chevauchement de texte
)
```

Il s'agit d'une représentation des individus catégorisé de par leurs valeurs du cos2. On remarque les points présentant des similarité sont regroupés. On remarque 6 foyers. (Nous précisons foyers sans aucun cas faire allusion à des partitions ou classes)

![](ind_jaffe.png)


***

**Mnist data**

Obs :
---

```{r,results='hide',message=FALSE,warning=FALSE}
pca.mnist <- PCA(mnist.data)
```

***

**Mfeat data**

Obs :
---

```{r,results='hide',message=FALSE,warning=FALSE}
pca.mfeat <- PCA(mfeat.data)
```

## 4. Clustering avec package Nbclust 

*En bref : Le package NbClust inclus une fonction NbClust() qui utilise 30 indices pour déterminer le nombre de clusters et propose d'utiliser le meilleur schéma de clusters à partir des différents résultats obtenus en faisant varier toutes les combinaisons de nombre de clusters (renseigné ou non au préalable par les param min.nc et max.nc) de mesures de distance et de méthodes de clusters.*

**Coil data**


Obs : 

```{r,results='hide',message=FALSE,warning=FALSE}
kmeans.coil = NbClust(data = coil.data, method = "kmeans",min.nc = 5,max.nc = 10)
kmeans.coil.part = kmeans.coil$Best.partition

average.coil =NbClust(data = coil.data, method = "average",min.nc = 5,max.nc = 10)
average.coil.part =average.coil$Best.partition

ward.coil = NbClust(data = coil.data, method = "ward.D",min.nc = 5,max.nc = 10)
ward.coil.part = ward.coil$Best.partition

single.coil = NbClust(data = coil.data, method = "single",min.nc = 5,max.nc = 10)
single.coil.part = single.coil$Best.partition

complete.coil = NbClust(data = coil.data, method = "complete",min.nc = 5,max.nc = 10)
complete.coil.part = complete.coil$Best.partition
```

***

**jaffe data**

Obs : 

```{r,results='hide',message=FALSE,warning=FALSE}
kmeans.jaffe = NbClust(data = jaffe.data, method = "kmeans")
kmeans.jaffe.part = kmeans.jaffe$Best.partition

average.jaffe =NbClust(data = jaffe.data, method = "average")
average.jaffe.part =average.jaffe$Best.partition

ward.jaffe = NbClust(data = jaffe.data, method = "ward.D")
ward.jaffe.part = ward.jaffe$Best.partition

single.jaffe = NbClust(data = jaffe.data, method = "single")
single.jaffe.part = single.jaffe$Best.partition

complete.jaffe = NbClust(data = jaffe.data, method = "complete")
complete.jaffe.part = complete.jaffe$Best.partition
```

***

**mfeat data**

Obs : 

```{r}
kmeans.mfeat = NbClust(data = mfeat.data, method = "kmeans")
kmeans.mfeat.part = kmeans.mfeat$Best.partition

average.mfeat =NbClust(data = mfeat.data, method = "average")
average.mfeat.part =average.mfeat$Best.partition

ward.mfeat = NbClust(data = mfeat.data, method = "ward.D")
ward.mfeat.part = ward.mfeat$Best.partition

single.mfeat = NbClust(data = mfeat.data, method = "single")
single.mfeat.part = single.mfeat$Best.partition

complete.mfeat = NbClust(data = mfeat.data, method = "complete")
complete.mfeat.part = complete.mfeat$Best.partition
```

***

**mnist data** 

Obs : 

```{r}
kmeans.mnist = NbClust(data = mnist.data, method = "kmeans")
kmeans.mnist.part = kmeans.mnist$Best.partition

average.mnist =NbClust(data = mnist.data, method = "average")
average.mnist.part =average.mnist$Best.partition

ward.mnist = NbClust(data = mnist.data, method = "ward.D")
ward.mnist.part = ward.mnist$Best.partition

single.mnist = NbClust(data = mnist.data, method = "single")
single.mnist.part = single.mnist$Best.partition

complete.mnist = NbClust(data = mnist.data, method = "complete")
complete.mnist.part = complete.mnist$Best.partition
```


## 5. Clustering à partir des deux premère composantes

**Coil data**

Obs : 

```{r}
HCPC(pca.coil)
```

***

**Jaffe data** 

Obs : 

```{r}
HCPC(pca.jaffe)
```

***

**Mfeat data**

Obs : 

```{r}
HCPC(pca.mfeat)
```

***

**Mnist data**

Obs : 

```{r}
HCPC(pca.mnist)
```


## 6. Spectral clustering

**Coil data**

Obs : 

```{r}
n.cluster.coil = 9
spect.coil = specc(x = coil.data, n.cluster.coil)
```

***

**Jaffe data**

Obs : 

```{r}
n.cluster.jaffe = 9
spect.jaffe = specc(x = jaffe.data, n.cluster.jaffe)
```

***

**Mfeat data**

Obs : 

```{r}
n.cluster.mfeat = 9
spect.mfeat = specc(x = mfeat.data, n.cluster.mfeat)
```

***

**Mnist data** 

Obs : 

```{r}
n.cluster.mnist = 9
spect.mnist = specc(x = mnist.data, n.cluster.mnist)
```


## 7. Proposition d'un nombre de classes

**Coil data**

Proposition : 

**Jaffe data** 

Proposition : 

**Mfeat data** 

Proposition : 

**Mnist data** 

Proposition : 

## 8. Modèle de mélange

**Coil data**

Obs : 

```{r}
mclust.coil = Mclust(coil.data)
```

***

**Jaffe data** 

Obs : 

```{r}
n.cluster.jaffe = 9
spect.jaffe = specc(x = jaffe.data, n.cluster.jaffe)
```

***

**Mfeat data** 

Obs : 

```{r}
mclust.mfeat = Mclust(mfeat.data)
```

***

**Mnist data**

Obs : 

```{r}
n.cluster.mnist = 9
spect.mnist = specc(x = mnist.data, n.cluster.mnist)
```

## 9. MclustDR
## 10. Etudes comparatives des performances
## 11. Cluspa
